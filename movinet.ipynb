{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toCy3v03Dwx7"
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Hub Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:47:43.019536Z",
     "iopub.status.busy": "2024-01-17T12:47:43.019000Z",
     "iopub.status.idle": "2024-01-17T12:47:43.023465Z",
     "shell.execute_reply": "2024-01-17T12:47:43.022790Z"
    },
    "id": "QKe-ubNcDvgv",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:19.690776Z",
     "start_time": "2024-01-26T15:31:19.582833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFdPvlXBOdUN"
   },
   "source": [
    "# MoViNet for streaming action recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/movinet\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/movinet.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/hub/tutorials/movinet.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/google/collections/movinet/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub models</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vxk2Kbc_KSP"
   },
   "source": [
    "This tutorial demonstrates how to use a pretrained video classification model to classify an activity (such as dancing, swimming, biking etc) in the given video.   \n",
    "\n",
    "The model architecture used in this tutorial is called [MoViNet](https://arxiv.org/pdf/2103.11511.pdf) (Mobile Video Networks). MoVieNets are a family of efficient video classification models trained on huge dataset ([Kinetics 600](https://deepmind.com/research/open-source/kinetics)).\n",
    "\n",
    "In contrast to the [i3d models](https://tfhub.dev/s?q=i3d-kinetics) available on TF Hub, MoViNets also support frame-by-frame inference on streaming video. \n",
    "\n",
    "The pretrained models are available from [TF Hub](https://tfhub.dev/google/collections/movinet/1). The TF Hub collection also includes quantized models optimized for [TFLite](https://tensorflow.org/lite).\n",
    "\n",
    "The source for these models is available in the [TensorFlow Model Garden](https://github.com/tensorflow/models/tree/master/official/projects/movinet). This includes a [longer version of this tutorial](https://colab.sandbox.google.com/github/tensorflow/models/blob/master/official/projects/movinet/movinet_tutorial.ipynb) that also covers building and fine-tuning a MoViNet model. \n",
    "\n",
    "This MoViNet tutorial is part of a series of TensorFlow video tutorials. Here are the other three tutorials:\n",
    "\n",
    "- [Load video data](https://www.tensorflow.org/tutorials/load_data/video): This tutorial explains how to load and preprocess video data into a TensorFlow dataset pipeline from scratch.\n",
    "- [Build a 3D CNN model for video classification](https://www.tensorflow.org/tutorials/video/video_classification). Note that this tutorial uses a (2+1)D CNN that decomposes the spatial and temporal aspects of 3D data; if you are using volumetric data such as an MRI scan, consider using a 3D CNN instead of a (2+1)D CNN.\n",
    "- [Transfer learning for video classification with MoViNet](https://www.tensorflow.org/tutorials/video/transfer_learning_with_movinet): This tutorial explains how to use a pre-trained video classification model trained on a different dataset with the UCF-101 dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E96e1UKQ8uR"
   },
   "source": [
    "![jumping jacks plot](https://storage.googleapis.com/tf_model_garden/vision/movinet/artifacts/jumpingjacks_plot.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_oLnvJy7kz5"
   },
   "source": [
    "## Setup\n",
    "\n",
    "For inference on smaller models (A0-A2), CPU is sufficient for this Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:47:43.027223Z",
     "iopub.status.busy": "2024-01-17T12:47:43.026780Z",
     "iopub.status.idle": "2024-01-17T12:48:00.127463Z",
     "shell.execute_reply": "2024-01-17T12:48:00.126376Z"
    },
    "id": "GUgUMGmY1yq-",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:19.705961Z",
     "start_time": "2024-01-26T15:31:19.692979Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:00.131800Z",
     "iopub.status.busy": "2024-01-17T12:48:00.131486Z",
     "iopub.status.idle": "2024-01-17T12:48:05.217872Z",
     "shell.execute_reply": "2024-01-17T12:48:05.216738Z"
    },
    "id": "s3khsunT7kWa",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:19.714570Z",
     "start_time": "2024-01-26T15:31:19.706174Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:05.222496Z",
     "iopub.status.busy": "2024-01-17T12:48:05.221871Z",
     "iopub.status.idle": "2024-01-17T12:48:08.320359Z",
     "shell.execute_reply": "2024-01-17T12:48:08.319542Z"
    },
    "id": "dI_1csl6Q-gH",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:21.819843Z",
     "start_time": "2024-01-26T15:31:19.715280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pathlib\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tqdm\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    'font.size': 10,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pn8K9oWbmREi"
   },
   "source": [
    "Get the kinetics 600 label list, and print the first few labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:08.325006Z",
     "iopub.status.busy": "2024-01-17T12:48:08.324262Z",
     "iopub.status.idle": "2024-01-17T12:48:08.494622Z",
     "shell.execute_reply": "2024-01-17T12:48:08.493646Z"
    },
    "id": "2VJUAcjhkfb3",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:21.826940Z",
     "start_time": "2024-01-26T15:31:21.821770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['abseiling', 'acting in play', 'adjusting glasses', 'air drumming',\n       'alligator wrestling', 'answering questions', 'applauding',\n       'applying cream', 'archaeological excavation', 'archery',\n       'arguing', 'arm wrestling', 'arranging flowers',\n       'assembling bicycle', 'assembling computer',\n       'attending conference', 'auctioning', 'backflip (human)',\n       'baking cookies', 'bandaging', 'barbequing', 'bartending',\n       'base jumping', 'bathing dog', 'battle rope training',\n       'beatboxing', 'bee keeping', 'belly dancing', 'bench pressing',\n       'bending back', 'bending metal', 'biking through snow',\n       'blasting sand', 'blowdrying hair', 'blowing bubble gum',\n       'blowing glass', 'blowing leaves', 'blowing nose',\n       'blowing out candles', 'bobsledding', 'bodysurfing', 'bookbinding',\n       'bottling', 'bouncing on bouncy castle', 'bouncing on trampoline',\n       'bowling', 'braiding hair', 'breading or breadcrumbing',\n       'breakdancing', 'breaking boards', 'breathing fire',\n       'brush painting', 'brushing hair', 'brushing teeth',\n       'building cabinet', 'building lego', 'building sandcastle',\n       'building shed', 'bull fighting', 'bulldozing', 'bungee jumping',\n       'burping', 'busking', 'calculating', 'calligraphy',\n       'canoeing or kayaking', 'capoeira', 'capsizing', 'card stacking',\n       'card throwing', 'carrying baby', 'cartwheeling', 'carving ice',\n       'carving pumpkin', 'casting fishing line', 'catching fish',\n       'catching or throwing baseball', 'catching or throwing frisbee',\n       'catching or throwing softball', 'celebrating',\n       'changing gear in car', 'changing oil',\n       'changing wheel (not on bike)', 'checking tires', 'cheerleading',\n       'chewing gum', 'chiseling stone', 'chiseling wood',\n       'chopping meat', 'chopping vegetables', 'chopping wood',\n       'clam digging', 'clapping', 'clay pottery making',\n       'clean and jerk', 'cleaning gutters', 'cleaning pool',\n       'cleaning shoes', 'cleaning toilet', 'cleaning windows',\n       'climbing a rope', 'climbing ladder', 'climbing tree',\n       'coloring in', 'combing hair', 'contact juggling', 'contorting',\n       'cooking egg', 'cooking on campfire',\n       'cooking sausages (not on barbeque)', 'cooking scallops',\n       'cosplaying', 'counting money', 'country line dancing',\n       'cracking back', 'cracking knuckles', 'cracking neck',\n       'crawling baby', 'crossing eyes', 'crossing river', 'crying',\n       'cumbia', 'curling (sport)', 'curling hair', 'cutting apple',\n       'cutting nails', 'cutting orange', 'cutting pineapple',\n       'cutting watermelon', 'dancing ballet', 'dancing charleston',\n       'dancing gangnam style', 'dancing macarena', 'deadlifting',\n       'decorating the christmas tree', 'delivering mail', 'dining',\n       'directing traffic', 'disc golfing', 'diving cliff',\n       'docking boat', 'dodgeball', 'doing aerobics',\n       'doing jigsaw puzzle', 'doing laundry', 'doing nails', 'drawing',\n       'dribbling basketball', 'drinking shots', 'driving car',\n       'driving tractor', 'drooling', 'drop kicking', 'drumming fingers',\n       'dumpster diving', 'dunking basketball', 'dyeing eyebrows',\n       'dyeing hair', 'eating burger', 'eating cake', 'eating carrots',\n       'eating chips', 'eating doughnuts', 'eating hotdog',\n       'eating ice cream', 'eating spaghetti', 'eating watermelon',\n       'egg hunting', 'embroidering', 'exercising with an exercise ball',\n       'extinguishing fire', 'faceplanting', 'falling off bike',\n       'falling off chair', 'feeding birds', 'feeding fish',\n       'feeding goats', 'fencing (sport)', 'fidgeting', 'finger snapping',\n       'fixing bicycle', 'fixing hair', 'flint knapping',\n       'flipping pancake', 'fly tying', 'flying kite', 'folding clothes',\n       'folding napkins', 'folding paper', 'front raises',\n       'frying vegetables', 'geocaching', 'getting a haircut',\n       'getting a piercing', 'getting a tattoo',\n       'giving or receiving award', 'gold panning', 'golf chipping',\n       'golf driving', 'golf putting', 'gospel singing in church',\n       'grinding meat', 'grooming dog', 'grooming horse',\n       'gymnastics tumbling', 'hammer throw', 'hand washing clothes',\n       'head stand', 'headbanging', 'headbutting', 'high jump',\n       'high kick', 'historical reenactment', 'hitting baseball',\n       'hockey stop', 'holding snake', 'home roasting coffee',\n       'hopscotch', 'hoverboarding', 'huddling', 'hugging (not baby)',\n       'hugging baby', 'hula hooping', 'hurdling', 'hurling (sport)',\n       'ice climbing', 'ice fishing', 'ice skating', 'ice swimming',\n       'inflating balloons', 'installing carpet', 'ironing',\n       'ironing hair', 'javelin throw', 'jaywalking', 'jetskiing',\n       'jogging', 'juggling balls', 'juggling fire',\n       'juggling soccer ball', 'jumping bicycle', 'jumping into pool',\n       'jumping jacks', 'jumpstyle dancing', 'karaoke',\n       'kicking field goal', 'kicking soccer ball', 'kissing',\n       'kitesurfing', 'knitting', 'krumping', 'land sailing', 'laughing',\n       'lawn mower racing', 'laying bricks', 'laying concrete',\n       'laying stone', 'laying tiles', 'leatherworking', 'licking',\n       'lifting hat', 'lighting fire', 'lock picking', 'long jump',\n       'longboarding', 'looking at phone', 'luge', 'lunge',\n       'making a cake', 'making a sandwich', 'making balloon shapes',\n       'making bubbles', 'making cheese', 'making horseshoes',\n       'making jewelry', 'making paper aeroplanes', 'making pizza',\n       'making snowman', 'making sushi', 'making tea', 'making the bed',\n       'marching', 'marriage proposal', 'massaging back',\n       'massaging feet', 'massaging legs', 'massaging neck',\n       \"massaging person's head\", 'milking cow', 'moon walking',\n       'mopping floor', 'mosh pit dancing', 'motorcycling',\n       'mountain climber (exercise)', 'moving furniture', 'mowing lawn',\n       'mushroom foraging', 'needle felting', 'news anchoring',\n       'opening bottle (not wine)', 'opening door', 'opening present',\n       'opening refrigerator', 'opening wine bottle', 'packing',\n       'paragliding', 'parasailing', 'parkour',\n       'passing American football (in game)',\n       'passing american football (not in game)', 'passing soccer ball',\n       'peeling apples', 'peeling potatoes', 'person collecting garbage',\n       'petting animal (not cat)', 'petting cat', 'photobombing',\n       'photocopying', 'picking fruit', 'pillow fight', 'pinching',\n       'pirouetting', 'planing wood', 'planting trees', 'plastering',\n       'playing accordion', 'playing badminton', 'playing bagpipes',\n       'playing basketball', 'playing bass guitar', 'playing beer pong',\n       'playing blackjack', 'playing cello', 'playing chess',\n       'playing clarinet', 'playing controller', 'playing cricket',\n       'playing cymbals', 'playing darts', 'playing didgeridoo',\n       'playing dominoes', 'playing drums', 'playing field hockey',\n       'playing flute', 'playing gong', 'playing guitar',\n       'playing hand clapping games', 'playing harmonica', 'playing harp',\n       'playing ice hockey', 'playing keyboard', 'playing kickball',\n       'playing laser tag', 'playing lute', 'playing maracas',\n       'playing marbles', 'playing monopoly', 'playing netball',\n       'playing ocarina', 'playing organ', 'playing paintball',\n       'playing pan pipes', 'playing piano', 'playing pinball',\n       'playing ping pong', 'playing poker', 'playing polo',\n       'playing recorder', 'playing rubiks cube', 'playing saxophone',\n       'playing scrabble', 'playing squash or racquetball',\n       'playing tennis', 'playing trombone', 'playing trumpet',\n       'playing ukulele', 'playing violin', 'playing volleyball',\n       'playing with trains', 'playing xylophone', 'poking bellybutton',\n       'pole vault', 'polishing metal', 'popping balloons',\n       'pouring beer', 'preparing salad', 'presenting weather forecast',\n       'pull ups', 'pumping fist', 'pumping gas', 'punching bag',\n       'punching person (boxing)', 'push up', 'pushing car',\n       'pushing cart', 'pushing wheelbarrow', 'pushing wheelchair',\n       'putting in contact lenses', 'putting on eyeliner',\n       'putting on foundation', 'putting on lipstick',\n       'putting on mascara', 'putting on sari', 'putting on shoes',\n       'raising eyebrows', 'reading book', 'reading newspaper',\n       'recording music', 'repairing puncture', 'riding a bike',\n       'riding camel', 'riding elephant', 'riding mechanical bull',\n       'riding mule', 'riding or walking with horse', 'riding scooter',\n       'riding snow blower', 'riding unicycle', 'ripping paper',\n       'roasting marshmallows', 'roasting pig', 'robot dancing',\n       'rock climbing', 'rock scissors paper', 'roller skating',\n       'rolling pastry', 'rope pushdown', 'running on treadmill',\n       'sailing', 'salsa dancing', 'sanding floor', 'sausage making',\n       'sawing wood', 'scrambling eggs', 'scrapbooking', 'scrubbing face',\n       'scuba diving', 'separating eggs', 'setting table', 'sewing',\n       'shaking hands', 'shaking head', 'shaping bread dough',\n       'sharpening knives', 'sharpening pencil', 'shaving head',\n       'shaving legs', 'shearing sheep', 'shining flashlight',\n       'shining shoes', 'shooting basketball', 'shooting goal (soccer)',\n       'shopping', 'shot put', 'shoveling snow', 'shucking oysters',\n       'shuffling cards', 'shuffling feet', 'side kick',\n       'sign language interpreting', 'singing', 'sipping cup', 'situp',\n       'skateboarding', 'ski jumping', 'skiing crosscountry',\n       'skiing mono', 'skiing slalom', 'skipping rope', 'skipping stone',\n       'skydiving', 'slacklining', 'slapping', 'sled dog racing',\n       'sleeping', 'smashing', 'smelling feet', 'smoking',\n       'smoking hookah', 'smoking pipe', 'snatch weight lifting',\n       'sneezing', 'snorkeling', 'snowboarding', 'snowkiting',\n       'snowmobiling', 'somersaulting', 'spelunking', 'spinning poi',\n       'spray painting', 'springboard diving', 'square dancing', 'squat',\n       'standing on hands', 'staring', 'steer roping',\n       'sticking tongue out', 'stomping grapes', 'stretching arm',\n       'stretching leg', 'sucking lolly', 'surfing crowd',\n       'surfing water', 'sweeping floor', 'swimming backstroke',\n       'swimming breast stroke', 'swimming butterfly stroke',\n       'swimming front crawl', 'swing dancing', 'swinging baseball bat',\n       'swinging on something', 'sword fighting', 'sword swallowing',\n       'tackling', 'tagging graffiti', 'tai chi', 'talking on cell phone',\n       'tango dancing', 'tap dancing', 'tapping guitar', 'tapping pen',\n       'tasting beer', 'tasting food', 'tasting wine', 'testifying',\n       'texting', 'threading needle', 'throwing axe',\n       'throwing ball (not baseball or American football)',\n       'throwing discus', 'throwing knife', 'throwing snowballs',\n       'throwing tantrum', 'throwing water balloon', 'tickling',\n       'tie dying', 'tightrope walking', 'tiptoeing', 'tobogganing',\n       'tossing coin', 'training dog', 'trapezing',\n       'trimming or shaving beard', 'trimming shrubs', 'trimming trees',\n       'triple jump', 'twiddling fingers', 'tying bow tie',\n       'tying knot (not on a tie)', 'tying necktie', 'tying shoe laces',\n       'unboxing', 'unloading truck', 'using a microscope',\n       'using a paint roller', 'using a power drill',\n       'using a sledge hammer', 'using a wrench', 'using atm',\n       'using bagging machine', 'using circular saw', 'using inhaler',\n       'using puppets', 'using remote controller (not gaming)',\n       'using segway', 'vacuuming floor', 'visiting the zoo',\n       'wading through mud', 'wading through water', 'waiting in line',\n       'waking up', 'walking the dog', 'walking through snow',\n       'washing dishes', 'washing feet', 'washing hair', 'washing hands',\n       'watching tv', 'water skiing', 'water sliding', 'watering plants',\n       'waving hand', 'waxing back', 'waxing chest', 'waxing eyebrows',\n       'waxing legs', 'weaving basket', 'weaving fabric', 'welding',\n       'whistling', 'windsurfing', 'winking', 'wood burning (art)',\n       'wrapping present', 'wrestling', 'writing', 'yarn spinning',\n       'yawning', 'yoga', 'zumba'], dtype='<U49')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_path = tf.keras.utils.get_file(\n",
    "    fname='labels.txt',\n",
    "    origin='https://raw.githubusercontent.com/tensorflow/models/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/kinetics_600_labels.txt'\n",
    ")\n",
    "labels_path = pathlib.Path(labels_path)\n",
    "\n",
    "lines = labels_path.read_text().splitlines()\n",
    "KINETICS_600_LABELS = np.array([line.strip() for line in lines])\n",
    "KINETICS_600_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9BU5XsOmaq3"
   },
   "source": [
    "To provide a simple example video for classification, we can load a short gif of jumping jacks being performed.\n",
    "\n",
    "![jumping jacks](https://github.com/tensorflow/models/raw/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/jumpingjack.gif)\n",
    "\n",
    "Attribution: Footage shared by [Coach Bobby Bluford](https://www.youtube.com/watch?v=-AxHpj-EuPg) on YouTube under the CC-BY license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aFKMbr4mfSg"
   },
   "source": [
    "Download the gif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:08.498806Z",
     "iopub.status.busy": "2024-01-17T12:48:08.498107Z",
     "iopub.status.idle": "2024-01-17T12:48:09.086786Z",
     "shell.execute_reply": "2024-01-17T12:48:09.085914Z"
    },
    "id": "w62jqXhaSb15",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:21.829627Z",
     "start_time": "2024-01-26T15:31:21.826944Z"
    }
   },
   "outputs": [],
   "source": [
    "jumpingjack_url = 'https://github.com/tensorflow/models/raw/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/jumpingjack.gif'\n",
    "jumpingjack_path = tf.keras.utils.get_file(\n",
    "    fname='jumpingjack.gif',\n",
    "    origin=jumpingjack_url,\n",
    "    cache_dir='.', cache_subdir='.',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdRS_22PebfB"
   },
   "source": [
    "Define a function to read a gif file into a `tf.Tensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:09.090904Z",
     "iopub.status.busy": "2024-01-17T12:48:09.090189Z",
     "iopub.status.idle": "2024-01-17T12:48:09.095913Z",
     "shell.execute_reply": "2024-01-17T12:48:09.094964Z"
    },
    "id": "mPhmCu6oSi5f",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:21.835577Z",
     "start_time": "2024-01-26T15:31:21.830703Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Read and process a video\n",
    "def load_gif(file_path, image_size=(224, 224)):\n",
    "  \"\"\"Loads a gif file into a TF tensor.\n",
    "\n",
    "  Use images resized to match what's expected by your model.\n",
    "  The model pages say the \"A2\" models expect 224 x 224 images at 5 fps\n",
    "\n",
    "  Args:\n",
    "    file_path: path to the location of a gif file.\n",
    "    image_size: a tuple of target size.\n",
    "\n",
    "  Returns:\n",
    "    a video of the gif file\n",
    "  \"\"\"\n",
    "  # Load a gif file, convert it to a TF tensor\n",
    "  raw = tf.io.read_file(file_path)\n",
    "  video = tf.io.decode_gif(raw)\n",
    "  # Resize the video\n",
    "  video = tf.image.resize(video, image_size)\n",
    "  # change dtype to a float32\n",
    "  # Hub models always want images normalized to [0,1]\n",
    "  # ref: https://www.tensorflow.org/hub/common_signatures/images#input\n",
    "  video = tf.cast(video, tf.float32) / 255.\n",
    "  return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx7cZm8vpDJm"
   },
   "source": [
    "The video's shape is `(frames, height, width, colors)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:09.099456Z",
     "iopub.status.busy": "2024-01-17T12:48:09.099186Z",
     "iopub.status.idle": "2024-01-17T12:48:09.320466Z",
     "shell.execute_reply": "2024-01-17T12:48:09.319287Z"
    },
    "id": "E7k_PmbFSkHv",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:21.902406Z",
     "start_time": "2024-01-26T15:31:21.839928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 17:31:21.832494: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-01-26 17:31:21.832512: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-01-26 17:31:21.832516: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-01-26 17:31:21.832544: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-26 17:31:21.832559: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "TensorShape([13, 224, 224, 3])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jumpingjack=load_gif(jumpingjack_path)\n",
    "jumpingjack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcKFy3oedBvF"
   },
   "source": [
    "## How to use the model\n",
    "\n",
    "This section contains a walkthrough showing how to use the [models from TensorFlow Hub](https://tfhub.dev/google/collections/movinet/1). If you just want to see the models in action, skip to the next section.\n",
    "\n",
    "There are two versions of each model: `base` and `streaming`.\n",
    "\n",
    "* The `base` version takes a video as input, and returns the probabilities averaged over the frames.\n",
    "* The `streaming` version takes a video frame and an RNN state as input, and returns the predictions for that frame, and the new RNN state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQO6Zb8Hm-9q"
   },
   "source": [
    "### The base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfnYU20JnPqp"
   },
   "source": [
    "Download the [pretrained model from TensorFlow Hub](https://tfhub.dev/tensorflow/movinet/a2/base/kinetics-600/classification/3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:09.325576Z",
     "iopub.status.busy": "2024-01-17T12:48:09.324931Z",
     "iopub.status.idle": "2024-01-17T12:48:27.741585Z",
     "shell.execute_reply": "2024-01-17T12:48:27.740730Z"
    },
    "id": "FnpPo6HSR7qv",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:27.369063Z",
     "start_time": "2024-01-26T15:31:21.902509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.21 s, sys: 249 ms, total: 5.46 s\n",
      "Wall time: 5.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "id = 'a2'\n",
    "mode = 'base'\n",
    "version = '3'\n",
    "hub_url = f'https://tfhub.dev/tensorflow/movinet/{id}/{mode}/kinetics-600/classification/{version}'\n",
    "model = hub.load(hub_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvaFwKhxndmb"
   },
   "source": [
    "This version of the model has one `signature`. It takes an `image` argument which is a `tf.float32` with shape `(batch, frames, height, width, colors)`. It returns a dictionary containing one output: A `tf.float32` tensor of logits with shape `(batch, classes)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:27.745767Z",
     "iopub.status.busy": "2024-01-17T12:48:27.745065Z",
     "iopub.status.idle": "2024-01-17T12:48:27.753582Z",
     "shell.execute_reply": "2024-01-17T12:48:27.752638Z"
    },
    "id": "7GzZ4Y03T_gH",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:27.371746Z",
     "start_time": "2024-01-26T15:31:27.369863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Parameters:\n",
      "  image (KEYWORD_ONLY): TensorSpec(shape=(None, None, None, None, 3), dtype=tf.float32, name='image')\n",
      "Output Type:\n",
      "  Dict[['classifier_head', TensorSpec(shape=(None, 600), dtype=tf.float32, name='classifier_head')]]\n",
      "Captures:\n",
      "  11064421008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842075376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842148704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842148000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842148352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064420304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842147648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842146592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842146944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842147296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064420656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842146240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842145184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842145888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842145536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064419600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064419248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064418896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064418544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064419952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842107568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842107216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842106864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842144832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282550272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282550624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285099440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285099088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285090144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285098736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282549920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842105456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842105808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842106512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842106160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282549568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842104048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842105104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842104752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842104400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282548864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282548512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282548160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282547808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282549216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842115584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842115232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842114880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842115936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282547456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282547104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842114176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842113824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842114528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842113472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282546752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842112416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842112064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842113120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842112768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282664784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282664432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282664080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282663728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282665136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842095280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842094928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842094576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842094224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282663376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282663024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842093872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842093520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842093168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842092816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282662672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842091760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841960288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842092464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842092112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282661968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282661616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282628448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282628096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282662320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841959232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841958880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841959936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841959584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282627392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282627744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285089792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285089440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285089088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285088736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282625280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841958176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841957824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841957472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841958528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282624928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841956416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842021552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841957120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841956768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282627040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282626688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282626336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282625984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282624576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842020144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842021200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842020848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842020496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282625632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282611888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842018736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842019792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842019440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842019088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282611536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842018032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841956192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841955840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842018384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282610832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282610480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282610128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282609776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282611184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841954784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841954432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841955488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841955136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282609424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282609072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841953376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841953024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841954080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841953728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282608720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841952672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841952320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842009264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842008912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282599776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282599424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282599072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282598720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282608368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842008208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842007856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842007504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842008560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282598368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282598016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842006448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842006096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842007152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842006800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282597664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842029568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842029216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842005744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842029920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282596960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282596608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282596256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282595904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282597312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842028864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842028512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842028160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842027808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282558640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282558288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842027104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842026752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842026400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842027456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282557936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841972048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841971696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842026048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841972400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282557232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282556880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282556528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282556176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282557584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841970288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841971344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841970992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841970640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282555472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282555824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285088384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285087328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285088032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285087680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282555120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841969584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841969232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841968880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10841969936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282554720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064671392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064671040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064672096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064671744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282554016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282553664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282553312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282552960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282554368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064670688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064670336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064669984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064669632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282552608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282552256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064669280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064668928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064668576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064668224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282551904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064659280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064658928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064658576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064659632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282551200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282550848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282546352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282546000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282551552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064657520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064657168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064658224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064657872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282545648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282545296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064656112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064676192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064656816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064656464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282544944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064675840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064675488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064675136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064674784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282544240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282543888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282543536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282543184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282544592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064674080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064673728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064673376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064674432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282542832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282501472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064672320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064651440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064673024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064672672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282501120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064650032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064651088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064650736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064650384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282500416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282500064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282499712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282499360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282500768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064649680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064649328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064648976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064648624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282499008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282513232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064647920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064618848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064618496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064648272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282512880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064617440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064617088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064618144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064617792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282498656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282498304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282497952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282497600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282512528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064616736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064616384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064616032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064615680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282513584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282512176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064615328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064614976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064544944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064544592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282511824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064543888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064543536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064543184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064544240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282511120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282510768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282510416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282510064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282511472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064542128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064541776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064542832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064542480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282472800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282472448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064598016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064597664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064541424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064598368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282472096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064597312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064596960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064596608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064596256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282470688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282470336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282471392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282471040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282471744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064595552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064595200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064594848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064595904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282469984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282469632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064573264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064572912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064594496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064573616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282469280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064571504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064572560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064572208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064571856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282464432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282464080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282463728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282463376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282468928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064571152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064570800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064570448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064570096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282463024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282462672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064569344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064568992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064568640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064569696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282462320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064567584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064567232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064568288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064567936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282461616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282461264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282460912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282468704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282461968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064566880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064566528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064566176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064565824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282468352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282468000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064528560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064528208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064527856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064527504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282467648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064526800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064526448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064526096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064527152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282466944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282466592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282466240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282465888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282467296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064525040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285159776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064525744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064525392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282465536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282465184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285158720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285158368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285159424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285159072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282464832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285158016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285157664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285157312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285156960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282517328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282516976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282516624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282516272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282517680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285156256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285155904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285163696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285156608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282515568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282515920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285188448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285187568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285086976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285086624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282515216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285162288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285163344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285162992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285162640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282514864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285161936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285161584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285161232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285160880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282514160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842136416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842136064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842135712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11282514512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285160176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285151584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285151232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285160528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842135360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842135008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285150176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285149824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285150880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285150528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842134656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285149472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285149120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285148768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285148416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842133952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842133600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842133248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842132896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842134304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285148064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285147712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285143216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285142864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842132544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842170992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285142160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285141808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285141456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285142512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842170640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285140400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285140048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285141104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285140752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842172752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842172400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842172048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842171696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842173104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285139696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285135200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285134848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285134496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842171344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842170288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285134144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285133792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285133440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285133088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842169936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285132384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285132032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285131680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285132736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842140512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842140160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842139808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842139456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842169584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285117936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285131328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285118640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285118288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842139104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842138752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285116528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285117584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285117232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285116880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842138400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285116176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285115824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285115472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285115120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842137696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842137344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842136992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842136640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842138048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285114368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285114016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285113664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285114720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842078896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842078544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285112608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285112256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285113312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285112960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842078192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285111904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285111552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285111200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285110848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842077488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842077136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842076784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842076432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842077840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285102256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285101904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285101552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285101200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842076080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  10842075728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285100496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285100144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285099792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11285100848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064389696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064422064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064421712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  11064421360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "sig = model.signatures['serving_default']\n",
    "print(sig.pretty_printed_signature())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4Xny1ANomi4"
   },
   "source": [
    "To run this signature on the video you need to add the outer `batch` dimension to the video first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:27.757296Z",
     "iopub.status.busy": "2024-01-17T12:48:27.756808Z",
     "iopub.status.idle": "2024-01-17T12:48:31.483237Z",
     "shell.execute_reply": "2024-01-17T12:48:31.482290Z"
    },
    "id": "LBOFEDG1XvZE",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:28.568907Z",
     "start_time": "2024-01-26T15:31:27.372619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 17:31:27.418965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-01-26 17:31:27.849387: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : NOT_FOUND: could not find registered platform with id: 0x12ff473d0\n",
      "2024-01-26 17:31:27.849410: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14292505131968791546\n",
      "2024-01-26 17:31:27.849414: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7316130086237760550\n",
      "2024-01-26 17:31:27.849418: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6504376573247364670\n",
      "2024-01-26 17:31:27.849421: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4575279305871454004\n",
      "2024-01-26 17:31:27.849428: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16098303251096979503\n",
      "2024-01-26 17:31:27.849431: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 767117977316914601\n",
      "2024-01-26 17:31:27.849435: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8595310544801678715\n",
      "2024-01-26 17:31:27.849447: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10701377983871002119\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node movinet_classifier/movinet/stem/stem/conv3d/StatefulPartitionedCall defined at (most recent call last):\n<stack traces unavailable>\nDetected at node movinet_classifier/movinet/stem/stem/conv3d/StatefulPartitionedCall defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  could not find registered platform with id: 0x12ff473d0\n\t [[{{node movinet_classifier/movinet/stem/stem/conv3d/StatefulPartitionedCall}}]]\n\t [[StatefulPartitionedCall/movinet_classifier/movinet/b0/l2/bneck/add/_18]]\n  (1) NOT_FOUND:  could not find registered platform with id: 0x12ff473d0\n\t [[{{node movinet_classifier/movinet/stem/stem/conv3d/StatefulPartitionedCall}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_signature_wrapper_38616]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#warmup\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43msig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mjumpingjack\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnewaxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1171\u001B[0m, in \u001B[0;36mConcreteFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1122\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Executes the wrapped function.\u001B[39;00m\n\u001B[1;32m   1123\u001B[0m \n\u001B[1;32m   1124\u001B[0m \u001B[38;5;124;03m  ConcreteFunctions have two signatures:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1169\u001B[0m \u001B[38;5;124;03m    TypeError: If the arguments do not match the function's signature.\u001B[39;00m\n\u001B[1;32m   1170\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1171\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1180\u001B[0m, in \u001B[0;36mConcreteFunction._call_impl\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1179\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1180\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_structured_signature\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1181\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m structured_err:\n\u001B[1;32m   1182\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_with_structured_signature\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   1259\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1260\u001B[0m     function_type_utils\u001B[38;5;241m.\u001B[39mcanonicalize_function_inputs(\n\u001B[1;32m   1261\u001B[0m         args, kwargs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type)\n\u001B[1;32m   1262\u001B[0m )\n\u001B[1;32m   1263\u001B[0m filtered_flat_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m-> 1264\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:146\u001B[0m, in \u001B[0;36m_WrapperFunction._call_flat\u001B[0;34m(self, args, captured_inputs)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# cross-replica context\u001B[39;00m\n\u001B[1;32m    145\u001B[0m   captured_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(get_unused_handle, captured_inputs))\n\u001B[0;32m--> 146\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mNotFoundError\u001B[0m: Graph execution error:\n\nDetected at node movinet_classifier/movinet/stem/stem/conv3d/StatefulPartitionedCall defined at (most recent call last):\n<stack traces unavailable>\nDetected at node movinet_classifier/movinet/stem/stem/conv3d/StatefulPartitionedCall defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  could not find registered platform with id: 0x12ff473d0\n\t [[{{node movinet_classifier/movinet/stem/stem/conv3d/StatefulPartitionedCall}}]]\n\t [[StatefulPartitionedCall/movinet_classifier/movinet/b0/l2/bneck/add/_18]]\n  (1) NOT_FOUND:  could not find registered platform with id: 0x12ff473d0\n\t [[{{node movinet_classifier/movinet/stem/stem/conv3d/StatefulPartitionedCall}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_signature_wrapper_38616]"
     ]
    }
   ],
   "source": [
    "#warmup\n",
    "sig(image = jumpingjack[tf.newaxis, :1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:31.488044Z",
     "iopub.status.busy": "2024-01-17T12:48:31.487345Z",
     "iopub.status.idle": "2024-01-17T12:48:46.325109Z",
     "shell.execute_reply": "2024-01-17T12:48:46.324182Z"
    },
    "id": "jCeW3KycVbGn",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:28.587997Z",
     "start_time": "2024-01-26T15:31:28.570021Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logits = sig(image = jumpingjack[tf.newaxis, ...])\n",
    "logits = logits['classifier_head'][0]\n",
    "\n",
    "print(logits.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE8doqkPpxED"
   },
   "source": [
    "Define a `get_top_k` function that packages the above output processing for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:46.329609Z",
     "iopub.status.busy": "2024-01-17T12:48:46.328901Z",
     "iopub.status.idle": "2024-01-17T12:48:46.335227Z",
     "shell.execute_reply": "2024-01-17T12:48:46.334395Z"
    },
    "id": "OozPNO6LvZ00",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.571171Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Get top_k labels and probabilities\n",
    "def get_top_k(probs, k=5, label_map=KINETICS_600_LABELS):\n",
    "  \"\"\"Outputs the top k model labels and probabilities on the given video.\n",
    "\n",
    "  Args:\n",
    "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
    "      the probability of each class on each frame.\n",
    "    k: the number of top predictions to select.\n",
    "    label_map: a list of labels to map logit indices to label strings.\n",
    "\n",
    "  Returns:\n",
    "    a tuple of the top-k labels and probabilities.\n",
    "  \"\"\"\n",
    "  # Sort predictions to find top_k\n",
    "  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n",
    "  # collect the labels of top_k predictions\n",
    "  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n",
    "  # decode lablels\n",
    "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
    "  # top_k probabilities of the predictions\n",
    "  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n",
    "  return tuple(zip(top_labels, top_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTfKMT29pP_Z"
   },
   "source": [
    "Convert the `logits` to probabilities, and look up the top 5 classes for the video. The model confirms that the video is probably of `jumping jacks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:46.339507Z",
     "iopub.status.busy": "2024-01-17T12:48:46.338727Z",
     "iopub.status.idle": "2024-01-17T12:48:46.354174Z",
     "shell.execute_reply": "2024-01-17T12:48:46.353286Z"
    },
    "id": "Z-SrNGsGV5Mt",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.572502Z"
    }
   },
   "outputs": [],
   "source": [
    "probs = tf.nn.softmax(logits, axis=-1)\n",
    "for label, p in get_top_k(probs):\n",
    "  print(f'{label:20s}: {p:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltdijoQpqjxZ"
   },
   "source": [
    "### The streaming model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dqdUPQXq45b"
   },
   "source": [
    "The previous section used a model that runs over a whole video. Often when processing a video you don't want a single prediction at the end, you want to update predictions frame by frame. The `stream` versions of the model allow you to do this.\n",
    "\n",
    "Load the `stream` version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:48:46.358775Z",
     "iopub.status.busy": "2024-01-17T12:48:46.357995Z",
     "iopub.status.idle": "2024-01-17T12:49:41.602199Z",
     "shell.execute_reply": "2024-01-17T12:49:41.601025Z"
    },
    "id": "mxt0hRXFZkAM",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.573718Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "id = 'a2'\n",
    "mode = 'stream'\n",
    "version = '3'\n",
    "hub_url = f'https://tfhub.dev/tensorflow/movinet/{id}/{mode}/kinetics-600/classification/{version}'\n",
    "model = hub.load(hub_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDswtsGgsYGS"
   },
   "source": [
    "Using this model is slightly more complex than the `base` model. You have to keep track of the internal state of the model's RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:41.608142Z",
     "iopub.status.busy": "2024-01-17T12:49:41.607706Z",
     "iopub.status.idle": "2024-01-17T12:49:41.613987Z",
     "shell.execute_reply": "2024-01-17T12:49:41.613037Z"
    },
    "id": "0fM_Vb1VsbDm",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.575156Z"
    }
   },
   "outputs": [],
   "source": [
    "list(model.signatures.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojr1_iYCtPvp"
   },
   "source": [
    "The `init_states` signature takes the video's **shape** `(batch, frames, height, width, colors)` as input, and returns a large dictionary of tensors containing the initial RNN states: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:41.617917Z",
     "iopub.status.busy": "2024-01-17T12:49:41.617364Z",
     "iopub.status.idle": "2024-01-17T12:49:41.623605Z",
     "shell.execute_reply": "2024-01-17T12:49:41.622622Z"
    },
    "id": "67loYFGpo_RP",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.576504Z"
    }
   },
   "outputs": [],
   "source": [
    "lines = model.signatures['init_states'].pretty_printed_signature().splitlines()\n",
    "lines = lines[:10]\n",
    "lines.append('      ...')\n",
    "print('.\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:41.627557Z",
     "iopub.status.busy": "2024-01-17T12:49:41.626919Z",
     "iopub.status.idle": "2024-01-17T12:49:41.987399Z",
     "shell.execute_reply": "2024-01-17T12:49:41.986403Z"
    },
    "id": "v5lG3vejn5df",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.577900Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_state = model.init_states(jumpingjack[tf.newaxis, ...].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:41.992228Z",
     "iopub.status.busy": "2024-01-17T12:49:41.991555Z",
     "iopub.status.idle": "2024-01-17T12:49:41.997866Z",
     "shell.execute_reply": "2024-01-17T12:49:41.996759Z"
    },
    "id": "J3DwmyHnuhH_",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.579326Z"
    }
   },
   "outputs": [],
   "source": [
    "type(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:42.002279Z",
     "iopub.status.busy": "2024-01-17T12:49:42.001507Z",
     "iopub.status.idle": "2024-01-17T12:49:42.008037Z",
     "shell.execute_reply": "2024-01-17T12:49:42.006957Z"
    },
    "id": "K8SyiEU6tB-e",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.580909Z"
    }
   },
   "outputs": [],
   "source": [
    "list(sorted(initial_state.keys()))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeMCzJMBvwRF"
   },
   "source": [
    "Once you have the initial state for the RNNs, you can pass the state and a video frame as input (keeping the `(batch, frames, height, width, colors)` shape for the video frame). The model returns a `(logits, state)` pair. \n",
    "\n",
    "After just seeing the first frame, the model is not convinced that the video is of \"jumping jacks\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:42.012753Z",
     "iopub.status.busy": "2024-01-17T12:49:42.012003Z",
     "iopub.status.idle": "2024-01-17T12:49:42.018653Z",
     "shell.execute_reply": "2024-01-17T12:49:42.017807Z"
    },
    "id": "McSLdIgtsI3d",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.582224Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = initial_state.copy()\n",
    "\n",
    "# Add the batch axis, take the first frme, but keep the frame-axis.\n",
    "inputs['image'] = jumpingjack[tf.newaxis, 0:1, ...] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:42.023005Z",
     "iopub.status.busy": "2024-01-17T12:49:42.022267Z",
     "iopub.status.idle": "2024-01-17T12:49:48.473774Z",
     "shell.execute_reply": "2024-01-17T12:49:48.472857Z"
    },
    "id": "WlH7PqLPX664",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.583558Z"
    }
   },
   "outputs": [],
   "source": [
    "# warmup\n",
    "model(inputs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:48.478777Z",
     "iopub.status.busy": "2024-01-17T12:49:48.477981Z",
     "iopub.status.idle": "2024-01-17T12:49:48.544169Z",
     "shell.execute_reply": "2024-01-17T12:49:48.543052Z"
    },
    "id": "7uzNXtu7X5sr",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.584909Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, new_state = model(inputs)\n",
    "logits = logits[0]\n",
    "probs = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "for label, p in get_top_k(probs):\n",
    "  print(f'{label:20s}: {p:.3f}')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLU644FQwXSb"
   },
   "source": [
    "If you run the model in a loop, passing the updated state with each frame, the model quickly converges to the correct result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:48.548627Z",
     "iopub.status.busy": "2024-01-17T12:49:48.547882Z",
     "iopub.status.idle": "2024-01-17T12:49:49.279631Z",
     "shell.execute_reply": "2024-01-17T12:49:49.278752Z"
    },
    "id": "Fzm7T4ImmIEg",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.585784Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "state = initial_state.copy()\n",
    "all_logits = []\n",
    "\n",
    "for n in range(len(jumpingjack)):\n",
    "  inputs = state\n",
    "  inputs['image'] = jumpingjack[tf.newaxis, n:n+1, ...]\n",
    "  result, state = model(inputs)\n",
    "  all_logits.append(logits)\n",
    "\n",
    "probabilities = tf.nn.softmax(all_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:49.283471Z",
     "iopub.status.busy": "2024-01-17T12:49:49.282865Z",
     "iopub.status.idle": "2024-01-17T12:49:49.289635Z",
     "shell.execute_reply": "2024-01-17T12:49:49.288904Z"
    },
    "id": "B7UtHoSWcOT2",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.586500Z"
    }
   },
   "outputs": [],
   "source": [
    "for label, p in get_top_k(probabilities[-1]):\n",
    "  print(f'{label:20s}: {p:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:49.293151Z",
     "iopub.status.busy": "2024-01-17T12:49:49.292557Z",
     "iopub.status.idle": "2024-01-17T12:49:49.522898Z",
     "shell.execute_reply": "2024-01-17T12:49:49.522137Z"
    },
    "id": "6ffV3NhZcsrv",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.587184Z"
    }
   },
   "outputs": [],
   "source": [
    "id = tf.argmax(probabilities[-1])\n",
    "plt.plot(probabilities[:, id])\n",
    "plt.xlabel('Frame #')\n",
    "plt.ylabel(f\"p('{KINETICS_600_LABELS[id]}')\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7MZ_AfRW845"
   },
   "source": [
    "You may notice that the final probability is much more certain than in the previous section where you ran the `base` model. The `base` model returns an average of the predictions over the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:49.526969Z",
     "iopub.status.busy": "2024-01-17T12:49:49.526353Z",
     "iopub.status.idle": "2024-01-17T12:49:49.534024Z",
     "shell.execute_reply": "2024-01-17T12:49:49.533304Z"
    },
    "id": "0Wij4tsyW8dR",
    "ExecuteTime": {
     "end_time": "2024-01-26T15:31:28.593101Z",
     "start_time": "2024-01-26T15:31:28.588132Z"
    }
   },
   "outputs": [],
   "source": [
    "for label, p in get_top_k(tf.reduce_mean(probabilities, axis=0)):\n",
    "  print(f'{label:20s}: {p:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLUoC9ejggGo"
   },
   "source": [
    "## Animate the predictions over time\n",
    "\n",
    "The previous section went into some details about how to use these models. This section builds on top of that to produce some nice inference animations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnFqOXazoWgy"
   },
   "source": [
    "The hidden cell below to defines helper functions used in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:49.537898Z",
     "iopub.status.busy": "2024-01-17T12:49:49.537634Z",
     "iopub.status.idle": "2024-01-17T12:49:49.559014Z",
     "shell.execute_reply": "2024-01-17T12:49:49.558285Z"
    },
    "id": "dx55NK3ZoZeh",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.588810Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Get top_k labels and probabilities predicted using MoViNets streaming model\n",
    "def get_top_k_streaming_labels(probs, k=5, label_map=KINETICS_600_LABELS):\n",
    "  \"\"\"Returns the top-k labels over an entire video sequence.\n",
    "\n",
    "  Args:\n",
    "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
    "      the probability of each class on each frame.\n",
    "    k: the number of top predictions to select.\n",
    "    label_map: a list of labels to map logit indices to label strings.\n",
    "\n",
    "  Returns:\n",
    "    a tuple of the top-k probabilities, labels, and logit indices\n",
    "  \"\"\"\n",
    "  top_categories_last = tf.argsort(probs, -1, 'DESCENDING')[-1, :1]\n",
    "  # Sort predictions to find top_k\n",
    "  categories = tf.argsort(probs, -1, 'DESCENDING')[:, :k]\n",
    "  categories = tf.reshape(categories, [-1])\n",
    "\n",
    "  counts = sorted([\n",
    "      (i.numpy(), tf.reduce_sum(tf.cast(categories == i, tf.int32)).numpy())\n",
    "      for i in tf.unique(categories)[0]\n",
    "  ], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  top_probs_idx = tf.constant([i for i, _ in counts[:k]])\n",
    "  top_probs_idx = tf.concat([top_categories_last, top_probs_idx], 0)\n",
    "  # find unique indices of categories\n",
    "  top_probs_idx = tf.unique(top_probs_idx)[0][:k+1]\n",
    "  # top_k probabilities of the predictions\n",
    "  top_probs = tf.gather(probs, top_probs_idx, axis=-1)\n",
    "  top_probs = tf.transpose(top_probs, perm=(1, 0))\n",
    "  # collect the labels of top_k predictions\n",
    "  top_labels = tf.gather(label_map, top_probs_idx, axis=0)\n",
    "  # decode the top_k labels\n",
    "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
    "\n",
    "  return top_probs, top_labels, top_probs_idx\n",
    "\n",
    "# Plot top_k predictions at a given time step\n",
    "def plot_streaming_top_preds_at_step(\n",
    "    top_probs,\n",
    "    top_labels,\n",
    "    step=None,\n",
    "    image=None,\n",
    "    legend_loc='lower left',\n",
    "    duration_seconds=10,\n",
    "    figure_height=500,\n",
    "    playhead_scale=0.8,\n",
    "    grid_alpha=0.3):\n",
    "  \"\"\"Generates a plot of the top video model predictions at a given time step.\n",
    "\n",
    "  Args:\n",
    "    top_probs: a tensor of shape (k, num_frames) representing the top-k\n",
    "      probabilities over all frames.\n",
    "    top_labels: a list of length k that represents the top-k label strings.\n",
    "    step: the current time step in the range [0, num_frames].\n",
    "    image: the image frame to display at the current time step.\n",
    "    legend_loc: the placement location of the legend.\n",
    "    duration_seconds: the total duration of the video.\n",
    "    figure_height: the output figure height.\n",
    "    playhead_scale: scale value for the playhead.\n",
    "    grid_alpha: alpha value for the gridlines.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of the output numpy image, figure, and axes.\n",
    "  \"\"\"\n",
    "  # find number of top_k labels and frames in the video\n",
    "  num_labels, num_frames = top_probs.shape\n",
    "  if step is None:\n",
    "    step = num_frames\n",
    "  # Visualize frames and top_k probabilities of streaming video\n",
    "  fig = plt.figure(figsize=(6.5, 7), dpi=300)\n",
    "  gs = mpl.gridspec.GridSpec(8, 1)\n",
    "  ax2 = plt.subplot(gs[:-3, :])\n",
    "  ax = plt.subplot(gs[-3:, :])\n",
    "  # display the frame\n",
    "  if image is not None:\n",
    "    ax2.imshow(image, interpolation='nearest')\n",
    "    ax2.axis('off')\n",
    "  # x-axis (frame number)\n",
    "  preview_line_x = tf.linspace(0., duration_seconds, num_frames)\n",
    "  # y-axis (top_k probabilities)\n",
    "  preview_line_y = top_probs\n",
    "\n",
    "  line_x = preview_line_x[:step+1]\n",
    "  line_y = preview_line_y[:, :step+1]\n",
    "\n",
    "  for i in range(num_labels):\n",
    "    ax.plot(preview_line_x, preview_line_y[i], label=None, linewidth='1.5',\n",
    "            linestyle=':', color='gray')\n",
    "    ax.plot(line_x, line_y[i], label=top_labels[i], linewidth='2.0')\n",
    "\n",
    "\n",
    "  ax.grid(which='major', linestyle=':', linewidth='1.0', alpha=grid_alpha)\n",
    "  ax.grid(which='minor', linestyle=':', linewidth='0.5', alpha=grid_alpha)\n",
    "\n",
    "  min_height = tf.reduce_min(top_probs) * playhead_scale\n",
    "  max_height = tf.reduce_max(top_probs)\n",
    "  ax.vlines(preview_line_x[step], min_height, max_height, colors='red')\n",
    "  ax.scatter(preview_line_x[step], max_height, color='red')\n",
    "\n",
    "  ax.legend(loc=legend_loc)\n",
    "\n",
    "  plt.xlim(0, duration_seconds)\n",
    "  plt.ylabel('Probability')\n",
    "  plt.xlabel('Time (s)')\n",
    "  plt.yscale('log')\n",
    "\n",
    "  fig.tight_layout()\n",
    "  fig.canvas.draw()\n",
    "\n",
    "  data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "  data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "  plt.close()\n",
    "\n",
    "  figure_width = int(figure_height * data.shape[1] / data.shape[0])\n",
    "  image = PIL.Image.fromarray(data).resize([figure_width, figure_height])\n",
    "  image = np.array(image)\n",
    "\n",
    "  return image\n",
    "\n",
    "# Plotting top_k predictions from MoViNets streaming model\n",
    "def plot_streaming_top_preds(\n",
    "    probs,\n",
    "    video,\n",
    "    top_k=5,\n",
    "    video_fps=25.,\n",
    "    figure_height=500,\n",
    "    use_progbar=True):\n",
    "  \"\"\"Generates a video plot of the top video model predictions.\n",
    "\n",
    "  Args:\n",
    "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
    "      the probability of each class on each frame.\n",
    "    video: the video to display in the plot.\n",
    "    top_k: the number of top predictions to select.\n",
    "    video_fps: the input video fps.\n",
    "    figure_fps: the output video fps.\n",
    "    figure_height: the height of the output video.\n",
    "    use_progbar: display a progress bar.\n",
    "\n",
    "  Returns:\n",
    "    A numpy array representing the output video.\n",
    "  \"\"\"\n",
    "  # select number of frames per second\n",
    "  video_fps = 8.\n",
    "  # select height of the image\n",
    "  figure_height = 500\n",
    "  # number of time steps of the given video\n",
    "  steps = video.shape[0]\n",
    "  # estimate duration of the video (in seconds)\n",
    "  duration = steps / video_fps\n",
    "  # estimate top_k probabilities and corresponding labels\n",
    "  top_probs, top_labels, _ = get_top_k_streaming_labels(probs, k=top_k)\n",
    "\n",
    "  images = []\n",
    "  step_generator = tqdm.trange(steps) if use_progbar else range(steps)\n",
    "  for i in step_generator:\n",
    "    image = plot_streaming_top_preds_at_step(\n",
    "        top_probs=top_probs,\n",
    "        top_labels=top_labels,\n",
    "        step=i,\n",
    "        image=video[i],\n",
    "        duration_seconds=duration,\n",
    "        figure_height=figure_height,\n",
    "    )\n",
    "    images.append(image)\n",
    "\n",
    "  return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLgFBslcZOQO"
   },
   "source": [
    "Start by running the streaming model across the frames of the video, and collecting the logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:49.562713Z",
     "iopub.status.busy": "2024-01-17T12:49:49.562116Z",
     "iopub.status.idle": "2024-01-17T12:49:49.794491Z",
     "shell.execute_reply": "2024-01-17T12:49:49.793635Z"
    },
    "id": "tXWR13wthnK5",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.589462Z"
    }
   },
   "outputs": [],
   "source": [
    "init_states = model.init_states(jumpingjack[tf.newaxis].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:49.798864Z",
     "iopub.status.busy": "2024-01-17T12:49:49.798279Z",
     "iopub.status.idle": "2024-01-17T12:49:50.520244Z",
     "shell.execute_reply": "2024-01-17T12:49:50.519143Z"
    },
    "id": "YqSkt7l8ltwt",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.590457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your video clip here\n",
    "video = jumpingjack\n",
    "images = tf.split(video[tf.newaxis], video.shape[0], axis=1)\n",
    "\n",
    "all_logits = []\n",
    "\n",
    "# To run on a video, pass in one frame at a time\n",
    "states = init_states\n",
    "for image in tqdm.tqdm(images):\n",
    "  # predictions for each frame\n",
    "  logits, states = model({**states, 'image': image})\n",
    "  all_logits.append(logits)\n",
    "\n",
    "# concatenating all the logits\n",
    "logits = tf.concat(all_logits, 0)\n",
    "# estimating probabilities\n",
    "probs = tf.nn.softmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:50.524681Z",
     "iopub.status.busy": "2024-01-17T12:49:50.523879Z",
     "iopub.status.idle": "2024-01-17T12:49:50.532006Z",
     "shell.execute_reply": "2024-01-17T12:49:50.531169Z"
    },
    "id": "OOGcCMMJyuPl",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.591218Z"
    }
   },
   "outputs": [],
   "source": [
    "final_probs = probs[-1]\n",
    "print('Top_k predictions and their probablities\\n')\n",
    "for label, p in get_top_k(final_probs):\n",
    "  print(f'{label:20s}: {p:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaybT0rbZct-"
   },
   "source": [
    "Convert the sequence of probabilities into a video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:50.536001Z",
     "iopub.status.busy": "2024-01-17T12:49:50.535328Z",
     "iopub.status.idle": "2024-01-17T12:49:57.580623Z",
     "shell.execute_reply": "2024-01-17T12:49:57.579763Z"
    },
    "id": "Xdox556CtMRb",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.591911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a plot and output to a video tensor\n",
    "plot_video = plot_streaming_top_preds(probs, video, video_fps=8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T12:49:57.584886Z",
     "iopub.status.busy": "2024-01-17T12:49:57.584050Z",
     "iopub.status.idle": "2024-01-17T12:49:57.924100Z",
     "shell.execute_reply": "2024-01-17T12:49:57.923012Z"
    },
    "id": "NSStKE9klCs3",
    "ExecuteTime": {
     "start_time": "2024-01-26T15:31:28.592639Z"
    }
   },
   "outputs": [],
   "source": [
    "# For gif format, set codec='gif'\n",
    "media.show_video(plot_video, fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCImgZ3OdJw7"
   },
   "source": [
    "## Resources\n",
    "\n",
    "The pretrained models are available from [TF Hub](https://tfhub.dev/google/collections/movinet/1). The TF Hub collection also includes quantized models optimized for [TFLite](https://tensorflow.org/lite).\n",
    "\n",
    "The source for these models is available in the [TensorFlow Model Garden](https://github.com/tensorflow/models/tree/master/official/projects/movinet). This includes a [longer version of this tutorial](https://colab.sandbox.google.com/github/tensorflow/models/blob/master/official/projects/movinet/movinet_tutorial.ipynb) that also covers building and fine-tuning a MoViNet model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh5lLAo-HpVF"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "To learn more about working with video data in TensorFlow, check out the following tutorials:\n",
    "\n",
    "* [Load video data](https://www.tensorflow.org/tutorials/load_data/video)\n",
    "* [Build a 3D CNN model for video classification](https://www.tensorflow.org/tutorials/video/video_classification)\n",
    "* [Transfer learning for video classification with MoViNet](https://www.tensorflow.org/tutorials/video/transfer_learning_with_movinet)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "movinet.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
