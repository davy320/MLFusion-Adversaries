{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pathlib\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tqdm\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    'font.size': 10,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file(\n",
    "    fname='labels.txt',\n",
    "    origin='https://raw.githubusercontent.com/tensorflow/models/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/kinetics_600_labels.txt'\n",
    ")\n",
    "labels_path = pathlib.Path(labels_path)\n",
    "\n",
    "lines = labels_path.read_text().splitlines()\n",
    "KINETICS_600_LABELS = np.array([line.strip() for line in lines])\n",
    "KINETICS_600_LABELS[:20]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "710898305dd9839a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "jumpingjack_url = 'https://github.com/tensorflow/models/raw/f8af2291cced43fc9f1d9b41ddbf772ae7b0d7d2/official/projects/movinet/files/jumpingjack.gif'\n",
    "jumpingjack_path = tf.keras.utils.get_file(\n",
    "    fname='jumpingjack.gif',\n",
    "    origin=jumpingjack_url,\n",
    "    cache_dir='.', cache_subdir='.',\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fab3742305141219",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([13, 224, 224, 3])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and process a video\n",
    "def load_gif(file_path, image_size=(224, 224)):\n",
    "  \"\"\"Loads a gif file into a TF tensor.\n",
    "\n",
    "  Use images resized to match what's expected by your model.\n",
    "  The model pages say the \"A2\" models expect 224 x 224 images at 5 fps\n",
    "\n",
    "  Args:\n",
    "    file_path: path to the location of a gif file.\n",
    "    image_size: a tuple of target size.\n",
    "\n",
    "  Returns:\n",
    "    a video of the gif file\n",
    "  \"\"\"\n",
    "  # Load a gif file, convert it to a TF tensor\n",
    "  raw = tf.io.read_file(file_path)\n",
    "  video = tf.io.decode_gif(raw)\n",
    "  # Resize the video\n",
    "  video = tf.image.resize(video, image_size)\n",
    "  # change dtype to a float32\n",
    "  # Hub models always want images normalized to [0,1]\n",
    "  # ref: https://www.tensorflow.org/hub/common_signatures/images#input\n",
    "  video = tf.cast(video, tf.float32) / 255.\n",
    "  return video\n",
    "\n",
    "jumpingjack=load_gif(jumpingjack_path)\n",
    "jumpingjack.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T16:32:55.857633Z",
     "start_time": "2024-01-26T16:32:55.821112Z"
    }
   },
   "id": "2cb97956e9542e6e",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Model to download\n",
    "id = 'a2'\n",
    "mode = 'base'\n",
    "version = '3'\n",
    "hub_url = f'https://tfhub.dev/tensorflow/movinet/{id}/{mode}/kinetics-600/classification/{version}'\n",
    "model = hub.load(hub_url)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5515851101e32af6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 18:34:08.057408: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : NOT_FOUND: could not find registered platform with id: 0x132ea3080\n",
      "2024-01-26 18:34:08.057431: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8428360859159746875\n",
      "2024-01-26 18:34:08.057435: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14652430089181197015\n",
      "2024-01-26 18:34:08.057440: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14781936511236714594\n",
      "2024-01-26 18:34:08.057442: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13454693340518515062\n",
      "2024-01-26 18:34:08.057446: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2653080372652776622\n",
      "2024-01-26 18:34:08.057449: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12674792846038674562\n",
      "2024-01-26 18:34:08.057457: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5533731342561166934\n",
      "2024-01-26 18:34:08.057461: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 485115404478782510\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node stem/conv3d/StatefulPartitionedCall defined at (most recent call last):\n<stack traces unavailable>\nDetected at node stem/conv3d/StatefulPartitionedCall defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  could not find registered platform with id: 0x132ea3080\n\t [[{{node stem/conv3d/StatefulPartitionedCall}}]]\n\t [[StatefulPartitionedCall/StatefulPartitionedCall/movinet/StatefulPartitionedCall/b0/l2/StatefulPartitionedCall/bneck/add/_18]]\n  (1) NOT_FOUND:  could not find registered platform with id: 0x132ea3080\n\t [[{{node stem/conv3d/StatefulPartitionedCall}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_170885]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Prepare the input in the expected dictionary format\u001B[39;00m\n\u001B[1;32m      4\u001B[0m model_input \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m: video_tensor_reshaped}\n\u001B[0;32m----> 6\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:816\u001B[0m, in \u001B[0;36m_call_attribute\u001B[0;34m(instance, *args, **kwargs)\u001B[0m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_attribute\u001B[39m(instance, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 816\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/sensor_vision/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mNotFoundError\u001B[0m: Graph execution error:\n\nDetected at node stem/conv3d/StatefulPartitionedCall defined at (most recent call last):\n<stack traces unavailable>\nDetected at node stem/conv3d/StatefulPartitionedCall defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  could not find registered platform with id: 0x132ea3080\n\t [[{{node stem/conv3d/StatefulPartitionedCall}}]]\n\t [[StatefulPartitionedCall/StatefulPartitionedCall/movinet/StatefulPartitionedCall/b0/l2/StatefulPartitionedCall/bneck/add/_18]]\n  (1) NOT_FOUND:  could not find registered platform with id: 0x132ea3080\n\t [[{{node stem/conv3d/StatefulPartitionedCall}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_170885]"
     ]
    }
   ],
   "source": [
    "video_tensor_reshaped = tf.reshape(jumpingjack, (1, *jumpingjack.shape))\n",
    "\n",
    "# Prepare the input in the expected dictionary format\n",
    "model_input = {'image': video_tensor_reshaped}\n",
    "\n",
    "predictions = model(model_input, False, None)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T16:34:08.087174Z",
     "start_time": "2024-01-26T16:34:07.350987Z"
    }
   },
   "id": "59717a0e74e09eeb",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_top_k(probs, k=5, label_map=KINETICS_600_LABELS):\n",
    "  \"\"\"Outputs the top k model labels and probabilities on the given video.\n",
    "\n",
    "  Args:\n",
    "    probs: probability tensor of shape (num_frames, num_classes) that represents\n",
    "      the probability of each class on each frame.\n",
    "    k: the number of top predictions to select.\n",
    "    label_map: a list of labels to map logit indices to label strings.\n",
    "\n",
    "  Returns:\n",
    "    a tuple of the top-k labels and probabilities.\n",
    "  \"\"\"\n",
    "  # Sort predictions to find top_k\n",
    "  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n",
    "  # collect the labels of top_k predictions\n",
    "  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n",
    "  # decode lablels\n",
    "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
    "  # top_k probabilities of the predictions\n",
    "  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n",
    "  return tuple(zip(top_labels, top_probs))\n",
    "\n",
    "logits = sig(image = jumpingjack[tf.newaxis, ...])\n",
    "logits = logits['classifier_head'][0]\n",
    "\n",
    "print(logits.shape)\n",
    "print()\n",
    "probs = tf.nn.softmax(logits, axis=-1)\n",
    "for label, p in get_top_k(probs):\n",
    "  print(f'{label:20s}: {p:.3f}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fffff3b1d0ec711",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c746efe11312828",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4f41f869f3d36f30"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
